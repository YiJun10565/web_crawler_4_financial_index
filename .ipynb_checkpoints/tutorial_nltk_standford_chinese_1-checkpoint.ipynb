{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請記得要先到 https://drive.google.com/drive/folders/1vwCTfeUuY5eAbqEdhmsayzEE6Bd7HSE6?usp=sharing \n",
    "下載整個「StanfordNLP」資料夾(名稱要一樣)，病根這份程式放在同一個目錄下，接著anaconda要安裝nltk，就可以開始使用啦!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPTokenizer\u001b[0m instead.'\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "副董事长 陈 焕光 ， 涉嫌 利用 假 交易 、 洗钱 等 方式 ， 在 台中 掏空 诚 美 材 子公司 茂 丰 贸易 公司 资产 约 2.6亿\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import StanfordSegmenter\n",
    "from nltk.tag import StanfordNERTagger\n",
    "#要記得將github上的StanfordNLP下載下來\n",
    "#這是比較直覺(攏長)的用法，直接指定路徑，而不設定環境變數\n",
    "segmenter = StanfordSegmenter(\n",
    "    java_class='edu.stanford.nlp.ie.crf.CRFClassifier',\n",
    "    path_to_jar=\"./StanfordNLP/jars/stanford-segmenter-3.9.2.jar\",\n",
    "    path_to_slf4j=\"./StanfordNLP/jars/slf4j-api.jar\",\n",
    "    path_to_sihan_corpora_dict=\"./StanfordNLP/stanford-segmenter-2018-10-16/data\",\n",
    "    path_to_model=\"./StanfordNLP/stanford-segmenter-2018-10-16/data/pku.gz\",\n",
    "    path_to_dict=\"./StanfordNLP/stanford-segmenter-2018-10-16/data/dict-chris6.ser.gz\"\n",
    ")\n",
    "res = segmenter.segment(u\"副董事长陈焕光，涉嫌利用假交易、洗钱等方式，在台中掏空诚美材子公司茂丰贸易公司资产约2.6亿\")\n",
    "\n",
    "print(type(res))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "副董事长 O\n",
      "陈 PERSON\n",
      "焕光 O\n",
      "， O\n",
      "涉嫌 O\n",
      "利用 O\n",
      "假 O\n",
      "交易 O\n",
      "、 O\n",
      "洗钱 O\n",
      "等 O\n",
      "方式 O\n",
      "， O\n",
      "在 O\n",
      "台中 GPE\n",
      "掏空 O\n",
      "诚 O\n",
      "美 O\n",
      "材 O\n",
      "子公司 O\n",
      "茂 O\n",
      "丰 O\n",
      "贸易 O\n",
      "公司 O\n",
      "资产 O\n",
      "约 O\n",
      "2.6亿 O\n"
     ]
    }
   ],
   "source": [
    "#這是比較直覺(攏長)的用法，直接指定路徑\n",
    "chi_tagger = StanfordNERTagger('./StanfordNLP/models/chinese.misc.distsim.crf.ser.gz',\n",
    "                              './StanfordNLP/jars/stanford-ner.jar')\n",
    "\n",
    "for word, tag in  chi_tagger.tag(res.split()):\n",
    "    print(word, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "刑事局 NN\n",
      "接获 VV\n",
      "中国 NR\n",
      "大陆 NN\n",
      "公安 NN\n",
      "通报 VV\n",
      "有 VE\n",
      "多起 VV\n",
      "假 JJ\n",
      "检警 NN\n",
      "诈骗 NN\n",
      "案 NN\n",
      "， PU\n",
      "经 P\n",
      "查 VV\n",
      "诈欺 NN\n",
      "集团 NN\n",
      "据点 NN\n",
      "遍布 VV\n",
      "台湾 NR\n",
      "北 NN\n",
      "中 LC\n",
      "南 NN\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordPOSTagger\n",
    "import os\n",
    "#這是比較直覺(攏長)的用法，直接指定路徑\n",
    "chi_tagger = StanfordPOSTagger('./StanfordNLP/models/chinese-distsim.tagger',\n",
    "                               './StanfordNLP/jars/stanford-ner.jar')\n",
    "sent = u'刑事局 接获 中国 大陆 公安 通报 有 多起 假 检警 诈骗 案 ， 经 查 诈欺 集团 据点 遍布 台湾 北 中 南 '\n",
    "for _, word_and_tag in  chi_tagger.tag(sent.split()):\n",
    "    word, tag = word_and_tag.split('#')\n",
    "    print(word , tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPTokenizer\u001b[0m instead.'\n"
     ]
    }
   ],
   "source": [
    "#這個cell 會先將to_convert的繁體字轉簡體後，再用StanfordSegmenter分詞，最後用StanfordParser將詞性與樹狀結構標註，並畫出來\n",
    "#轉成簡體字結果會比較準確\n",
    "import os\n",
    "from opencc import OpenCC\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk.tokenize import StanfordSegmenter\n",
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "\n",
    "#但遇到32行的「StanfordParser」的class，就必須要如 11-14 行一樣設定環境變數，不能再用上述偷懶直接指定路徑的方法\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Java\\\\jdk-11.0.1\"#注意這邊你們電腦要安裝java jdk，並放入你們自己的jdk的安裝路徑\n",
    "\n",
    "os.environ[\"CLASSPATH\"] = \"./StanfordNLP/jars\"\n",
    "os.environ[\"STANFORD_MODELS\"] = \"./StanfordNLP/models\"\n",
    "\n",
    "to_convert=\"刑事局接獲中國大陸公安通報有多起假檢警詐騙案，經查詐欺集團據點遍布台灣北中南\"\n",
    "cc = OpenCC('t2s')  # (Optional )convert from Simplified Chinese to Traditional Chinese\n",
    "content = cc.convert(to_convert)#一樣轉成簡體字，這樣Stanford的系統才會比較準確\n",
    "\n",
    "\n",
    "segmenter = StanfordSegmenter(\n",
    "    java_class='edu.stanford.nlp.ie.crf.CRFClassifier',\n",
    "    path_to_jar=\"./StanfordNLP/jars/stanford-segmenter-3.9.2.jar\",\n",
    "    path_to_slf4j=\"./StanfordNLP/jars/slf4j-api.jar\",\n",
    "    path_to_sihan_corpora_dict=\"./StanfordNLP/stanford-segmenter-2018-10-16/data\",\n",
    "    path_to_model=\"./StanfordNLP/stanford-segmenter-2018-10-16/data/pku.gz\",\n",
    "    path_to_dict=\"./StanfordNLP/stanford-segmenter-2018-10-16/data/dict-chris6.ser.gz\"\n",
    ")\n",
    "res = segmenter.segment(content)\n",
    "\n",
    "\n",
    "ch_parser = StanfordParser(model_path=u'./StanfordNLP/models/chinesePCFG.ser.gz')\n",
    "sentences  = ch_parser.parse(res.split())\n",
    "\n",
    "for line in sentences:\n",
    "    for sentence in line:\n",
    "        sentence.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['刑事', '局', '接获', '中国', '大陆', '公安', '通报', '有多起', '假检警', '诈骗案', '，', '经查', '诈欺', '集团', '据点', '遍布', '台湾', '北', '中南']\n"
     ]
    }
   ],
   "source": [
    "#這是斷詞系統用結疤，然後搭配StanfordParser的例子，你們可以與上一個cell做比較\n",
    "import jieba\n",
    "from opencc import OpenCC\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk.tokenize import StanfordSegmenter\n",
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "to_convert=\"刑事局接獲中國大陸公安通報有多起假檢警詐騙案，經查詐欺集團據點遍布台灣北中南\"\n",
    "cc = OpenCC('t2s')  # (Optional )convert from Simplified Chinese to Traditional Chinese\n",
    "content = cc.convert(to_convert)#一樣轉成簡體字，這樣Stanford的系統才會比較準確\n",
    "\n",
    "word_list = list(jieba.cut(content, cut_all=False))\n",
    "print(word_list)\n",
    "\n",
    "ch_parser = StanfordParser(model_path=u'./StanfordNLP/models/chinesePCFG.ser.gz')\n",
    "sentences  = ch_parser.parse(word_list)\n",
    "\n",
    "for line in sentences:\n",
    "    for sentence in line:\n",
    "        sentence.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
